<div align="center">

<!-- Local logo for reliability (placed in assets/) -->
<img src="assets/LOGO_DRAGONFLY_HD.jpg" alt="Dragonfly logo" width="120" style="background:#ffffff; padding:6px; border-radius:8px;" />

# üêâ Dragonfly MCP Server

Serveur MCP multi‚Äëoutils, rapide et extensible, propuls√© par FastAPI. D√©couverte automatique des tools, ex√©cution s√©curis√©e, orchestrateur LLM avanc√©, et panneau de contr√¥le web.

[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](./LICENSE)
![Python](https://img.shields.io/badge/Python-3.9%2B-3776AB)
![FastAPI](https://img.shields.io/badge/FastAPI-%F0%9F%9A%80-009688)
![Status](https://img.shields.io/badge/Status-Active-success)

</div>

---

## ‚ú® Vue d‚Äôensemble
Dragonfly MCP Server expose des ¬´ tools ¬ª (au format OpenAI tools) via des endpoints HTTP simples:
- D√©couverte automatique des outils sous `src/tools/`
- Ex√©cution d‚Äôun tool via `POST /execute`
- Orchestration LLM en 2 phases via `call_llm` (avec usage cumulatif)
- Panneau de contr√¥le web pour configurer et tester (`/control`)

> Pour les d√©tails d‚ÄôAPI (endpoints, s√©rialisation JSON, etc.), consultez aussi [src/README.md](./src/README.md).

---

## üìö Sommaire
- [Fonctionnalit√©s](#-fonctionnalit√©s)
- [Demo rapide](#-demo-rapide)
- [Installation](#-installation)
- [D√©marrage](#-d√©marrage)
- [Prerequis Python](#-prerequis-python)
- [Endpoints](#-endpoints)
- [Outils inclus](#-outils-inclus)
- [Orchestrateur LLM (call_llm)](#-orchestrateur-llm-call_llm)
- [Configuration](#-configuration)
- [S√©curit√©](#-s√©curit√©)
- [Structure du projet](#-structure-du-projet)
- [Pour les LLM ¬´ d√©veloppeurs ¬ª](#-pour-les-llm-d√©veloppeurs)
- [Feuille de route](#-feuille-de-route)
- [Licence](#-licence)

---

## üöÄ Fonctionnalit√©s
- Auto‚Äëreload des tools (d√©tection de nouveaux fichiers dans `src/tools/`)
- JSON ¬´ s√ªr ¬ª: grands entiers, NaN/Infinity sanitis√©s
- Orchestration LLM streaming en 2 phases (avec cumul d‚Äôusage multi‚Äëniveaux)
- Panneau de contr√¥le web (`/control`)
- Outils pr√™ts √† l‚Äôemploi: Git/GitHub, SQLite, PDF, Date/Heure, Math (HP), GitBook, Reddit, Universal Doc Scraper, Script Executor, etc.

---

## ‚ö° Demo rapide
Ex√©cuter un tool en une requ√™te:

```bash
curl -s -X POST http://127.0.0.1:8000/execute \
 -H 'Content-Type: application/json' \
 -d '{"tool":"date","params":{"operation":"today"}}'
```

Orchestrer un LLM (r√©ponse texte)¬†:

```bash
curl -s -X POST http://127.0.0.1:8000/execute \
 -H 'Content-Type: application/json' \
 -d '{
   "tool":"call_llm",
   "params":{ "message":"Dis bonjour en fran√ßais.", "model":"gpt-4o" }
 }'
```

Lister les tools disponibles:

```bash
curl -s http://127.0.0.1:8000/tools
```

---

## üõ† Installation
```bash
git clone https://github.com/FranckDubray/dragonfly-mcp-server.git
cd dragonfly-mcp-server
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\Activate.ps1
pip install -U pip
pip install -e ".[dev]"
```

## ‚ñ∂Ô∏è D√©marrage
- Linux/macOS: `./scripts/dev.sh`
- Windows: `scripts\dev.ps1`

Par d√©faut: http://127.0.0.1:8000

Panneau de contr√¥le: http://127.0.0.1:8000/control

---

## üêç Prerequis Python
- Version minimale recommand√©e: Python 3.11 ou 3.12.
- Le projet utilise des fonctionnalit√©s modernes (annotations/typing, comportement de json/ints, etc.) pouvant √©chouer avec des versions trop anciennes.
- Les scripts de d√©marrage v√©rifient automatiquement la version install√©e et abortent si la version est trop ancienne.

> Astuce: utilisez pyenv pour installer la bonne version, ou conda/mamba.

---

## üîó Endpoints
- `GET /tools` ‚Äî liste des tools (spec incluse). Ajouter `?reload=1` pour forcer un rescannage.
- `POST /execute` ‚Äî ex√©cuter un tool: `{ tool: string, params: object }`
- `GET /config` / `POST /config` ‚Äî lire/√©crire la configuration (.env)
- `GET /control` ‚Äî panneau HTML
- `GET /control.js` ‚Äî script du panneau

D√©tails √©tendus: [src/README.md](./src/README.md)

---

## üß™ Outils inclus
- `call_llm`: orchestrateur LLM (2 phases, usage cumulatif)
- `math`: calcul num√©rique/HP, symbolique, alg√®bre lin√©aire
- `date`: now/today, diff, add, format, parse, weekday, week_number
- `git`: GitHub API + Git local (op√©rations s√©curis√©es)
- `gitbook`: discovery/lecture/search GitBook
- `sqlite_db`: SQLite chroot (bases sous `<projet>/sqlite3`)
- `pdf_search` / `pdf2text`
- `reddit_intelligence`
- `universal_doc_scraper`
- `script_executor`: ex√©cution de scripts Python sandbox√©s orchestrant des tools

Specs JSON (OpenAI tools) correspondantes dans `src/tool_specs/`.

---

## üß† Orchestrateur LLM (`call_llm`)
- 1er stream (avec tools): collecte des `tool_calls`, ex√©cution c√¥t√© serveur
- 2e stream (sans tools): g√©n√©ration du texte final
- Usage cumulatif: additionne automatiquement les usages des 2 streams et de tous les appels imbriqu√©s (ex: A ‚Üí B ‚Üí sonar)
- Param√®tres cl√©s: `message`, `model`, `tool_names` (liste des tools expos√©s au mod√®le), `promptSystem`, `debug`

---

## ‚öôÔ∏è Configuration
Variables principales:
- R√©seau/serveur: `MCP_HOST`, `MCP_PORT`, `LOG_LEVEL`
- Ex√©cution: `EXECUTE_TIMEOUT_SEC`, `AUTO_RELOAD_TOOLS`, `RELOAD`
- LLM: `AI_PORTAL_TOKEN`, `LLM_ENDPOINT`, `LLM_REQUEST_TIMEOUT_SEC`, `LLM_RETURN_DEBUG`, `MCP_URL`
- JSON/entiers: `BIGINT_AS_STRING`, `BIGINT_STR_THRESHOLD`, `PY_INT_MAX_STR_DIGITS`
- Divers: `GITHUB_TOKEN`

Configurer via `/control` (recommand√©) ou via `.env`.

---

## üîí S√©curit√©
- SQLite chroot: DBs sous `<projet>/sqlite3` (noms valid√©s)
- Git local: op√©rations limit√©s √† la racine du projet
- `script_executor`: sandbox stricte (pas d‚Äôacc√®s non autoris√©)
- Safe JSON: s√©rialisation robuste (NaN/Infinity, tr√®s grands entiers)

---

## üóÇ Structure du projet
```
src/
  app_factory.py     # FastAPI app, endpoints, auto-reload, Safe JSON
  server.py          # Entr√©e (Uvicorn) ‚Äî cr√©e l‚Äôapp et lance le serveur
  config.py          # .env (load/save), masquage des secrets
  tools/             # Tous les tools (run() + spec())
    _call_llm/       # Orchestrateur LLM: core, payloads, streaming, http_client...
    _math/           # Arithm√©tique, symbolique, proba, alg√®bre lin√©aire, etc.
    _script/         # Sandbox du ScriptExecutor
  tool_specs/        # Specs JSON canoniques (OpenAI tools)
  README.md          # Doc API interne (endpoints + composants)
```

---

## üë©‚Äçüíª Pour les LLM ¬´ d√©veloppeurs ¬ª
Vous modifiez/√©tendez le d√©p√¥t ? Lisez ce guide:
- [LLM_DEV_GUIDE.md](./LLM_DEV_GUIDE.md)
  - Conventions, invariants, checklists, pi√®ges √† √©viter
  - R√®gles de spec JSON (parameters = object, arrays ‚Üí items)
  - D√©tails sur `call_llm` (streaming, usage cumulatif) et le JSON s√ªr

---

## üó∫Ô∏è Feuille de route (extraits)
- [ ] Tests automatis√©s (tools + orchestrateur)
- [ ] Exemples interactifs dans `/control`
- [ ] Int√©gration d‚Äôauth facultative sur les endpoints sensibles
- [ ] Export de m√©triques (Prometheus)

Contributions bienvenues ‚Äî issues & PRs !

---

## üìÑ Licence
MIT ‚Äî voir [LICENSE](./LICENSE)
