{
  "type": "function",
  "function": {
    "name": "call_llm",
    "displayName": "LLM Orchestrator",
    "description": "Appelle un modèle LLM en mode streaming. Peut orchestrer des tool_calls (MCP) sur un premier appel, exécuter les outils, puis faire un second appel pour produire la réponse finale en texte.",
    "parameters": {
      "type": "object",
      "properties": {
        "message": {
          "type": "string",
          "description": "Message utilisateur (contenu principal)."
        },
        "promptSystem": {
          "type": "string",
          "description": "Contexte système transmis séparément au payload (pas dans messages)."
        },
        "model": {
          "type": "string",
          "description": "Nom du modèle (obligatoire). Ex: gpt-5."
        },
        "max_tokens": {
          "type": "integer",
          "description": "Nombre maximum de tokens générés pour la réponse finale."
        },
        "tool_names": {
          "type": "array",
          "description": "Liste des outils MCP autorisés pour le 1er appel (ex: [\"math\"]).",
          "items": { "type": "string" }
        },
        "debug": {
          "type": "boolean",
          "description": "Quand true, inclut un bloc debug détaillé dans la réponse (payloads, SSE, exécutions MCP)."
        }
      },
      "required": ["message", "model"],
      "additionalProperties": false
    }
  }
}
