"""
üéì Academic Research Tool Super - Version multi-sources optimis√©e

Sources int√©gr√©es (cette impl√©mentation minimale active arXiv uniquement): arXiv
R√©ponses compactes pour pr√©server le contexte LLM
"""

import json
import urllib.request
import urllib.parse
import xml.etree.ElementTree as ET
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from pathlib import Path

ATOM_NS = {
    'atom': 'http://www.w3.org/2005/Atom',
    'arxiv': 'http://arxiv.org/schemas/atom'
}

@dataclass
class Author:
    name: str
    affiliation: str = ""

@dataclass
class ResearchResult:
    title: str
    authors: List[Author]
    abstract: str
    doi: str
    url: str
    publication_date: str
    journal: str
    source: str
    citations_count: int = 0
    full_text_url: str = ""


class AcademicResearchSuper:
    def __init__(self):
        self.headers = {
            'User-Agent': 'Academic-Research-Super/1.0 (Python; Educational Use)'
        }
        self.last_request: Dict[str, Any] = {}

    # ------------------- arXiv -------------------
    def _arxiv_build_url(self, query: str, start: int, max_results: int) -> str:
        # arXiv API: http://export.arxiv.org/api_help/
        # Param√®tres principaux: search_query, start, max_results, sortBy, sortOrder
        params = {
            'search_query': query,
            'start': str(start),
            'max_results': str(max_results),
            'sortBy': 'submittedDate',
            'sortOrder': 'descending',
        }
        return 'http://export.arxiv.org/api/query?' + urllib.parse.urlencode(params)

    def _arxiv_fetch(self, url: str) -> str:
        req = urllib.request.Request(url, headers=self.headers)
        with urllib.request.urlopen(req, timeout=20) as resp:
            return resp.read().decode('utf-8', errors='replace')

    def _arxiv_parse(self, xml_text: str) -> List[Dict[str, Any]]:
        results: List[Dict[str, Any]] = []
        try:
            root = ET.fromstring(xml_text)
            for entry in root.findall('atom:entry', ATOM_NS):
                title = (entry.findtext('atom:title', default='', namespaces=ATOM_NS) or '').strip()
                summary = (entry.findtext('atom:summary', default='', namespaces=ATOM_NS) or '').strip()
                id_url = entry.findtext('atom:id', default='', namespaces=ATOM_NS) or ''
                published = entry.findtext('atom:published', default='', namespaces=ATOM_NS) or ''
                # authors
                authors: List[Dict[str, str]] = []
                for a in entry.findall('atom:author', ATOM_NS):
                    nm = a.findtext('atom:name', default='', namespaces=ATOM_NS) or ''
                    if nm:
                        authors.append({'name': nm})
                # doi (arxiv:doi)
                doi = entry.findtext('arxiv:doi', default='', namespaces=ATOM_NS) or ''
                journal_ref = entry.findtext('arxiv:journal_ref', default='', namespaces=ATOM_NS) or ''
                # pdf link
                pdf_url = ''
                for link in entry.findall('atom:link', ATOM_NS):
                    if link.get('type') == 'application/pdf':
                        pdf_url = link.get('href') or ''
                        break
                # Compact output
                results.append({
                    'title': title,
                    'authors': authors,
                    'abstract': summary,
                    'doi': doi,
                    'url': id_url,
                    'publication_date': published,
                    'journal': journal_ref,
                    'source': 'arxiv',
                    'citations_count': 0,
                    'full_text_url': pdf_url,
                })
        except Exception:
            # En cas de probl√®me XML, retourner liste vide (le caller fournit un message)
            return []
        return results

    def arxiv_search(self, query: str, max_results: int = 10) -> Dict[str, Any]:
        url = self._arxiv_build_url(query=query, start=0, max_results=max_results)
        self.last_request = {'provider': 'arxiv', 'url': url}
        xml_text = self._arxiv_fetch(url)
        items = self._arxiv_parse(xml_text)
        return {
            'provider': 'arxiv',
            'count': len(items),
            'items': items,
            'request': self.last_request,
        }

    # ------------------- fa√ßade run -------------------
    def run(self, operation: str, **params) -> Dict[str, Any]:
        operation = (operation or 'search_papers').strip()
        sources = params.get('sources') or ['arxiv']
        if isinstance(sources, str):
            sources = [sources]
        max_results = int(params.get('max_results') or 10)
        query = str(params.get('query') or '').strip()

        if operation == 'search_papers':
            out_results: List[Dict[str, Any]] = []
            notes: List[str] = []
            if not query:
                return {"success": False, "error": "query requis"}
            # Actuellement, seule la source arXiv est impl√©ment√©e
            if 'arxiv' in [s.lower() for s in sources]:
                try:
                    data = self.arxiv_search(query=query, max_results=max_results)
                    out_results.extend(data.get('items', []))
                except Exception as e:
                    notes.append(f"arxiv error: {e}")
            unsupported = [s for s in sources if s.lower() not in ('arxiv',)]
            if unsupported:
                notes.append(f"sources non support√©es dans cette impl√©mentation: {unsupported}")
            return {
                "success": True,
                "results": out_results,
                "source_count": len(sources),
                "notes": notes or None
            }

        # Esquisses pour autres op√©rations
        if operation in ("get_paper_details", "search_authors", "get_citations"):
            return {"success": False, "error": f"operation '{operation}' non impl√©ment√©e dans cette version"}

        return {"success": False, "error": f"operation inconnue: {operation}"}


_tool = AcademicResearchSuper()

_SPEC_DIR = Path(__file__).resolve().parent.parent / "tool_specs"

def _load_spec_override(name: str) -> Dict[str, Any] | None:
    try:
        p = _SPEC_DIR / f"{name}.json"
        if p.is_file():
            with open(p, "r", encoding="utf-8") as f:
                return json.load(f)
    except Exception:
        pass
    return None

def run(**params) -> Dict[str, Any]:
    try:
        operation = params.get('operation', 'search_papers')
        return _tool.run(operation=operation, **params)
    except Exception as e:
        return {"success": False, "error": str(e)}

def spec() -> Dict[str, Any]:
    base = {
        "type": "function",
        "function": {
            "name": "academic_research_super",
            "displayName": "Research",
            "description": "Recherche acad√©mique multi-sources (impl√©mentation actuelle: arXiv).",
            "parameters": {
                "type": "object",
                "additionalProperties": True
            }
        }
    }
    override = _load_spec_override("academic_research_super")
    if override and isinstance(override, dict):
        fn = base.get("function", {})
        ofn = override.get("function", {})
        if ofn.get("displayName"):
            fn["displayName"] = ofn["displayName"]
        if ofn.get("description"):
            fn["description"] = ofn["description"]
        if ofn.get("parameters"):
            fn["parameters"] = ofn["parameters"]
    return base
