{
  "version": "1.0",
  "process_version": "2.1.0",
  "metadata": {
    "description": "AI/LLM Curation - Top 10 des 3 derniers jours (one-shot with EXIT)",
    "author": "orchestrator-curation-team",
    "features": [
      "Multi-source aggregation (News, Reddit, arXiv, Papers With Code)",
      "LLM-based scoring and ranking",
      "Top 10 selection with summaries",
      "Markdown report generation",
      "SQLite persistence",
      "One-shot execution with EXIT"
    ]
  },
  "worker_ctx": {
    "timezone": "UTC",
    "llm_model": "gpt-4o-mini",
    "llm_temperature": 0.3,
    "news_limit": 5,
    "reddit_limit_per_sub": 2,
    "arxiv_limit": 5
  },
  "graph": {
    "nodes": [
      {
        "name": "START",
        "type": "start"
      },
      {
        "name": "get_date_now",
        "type": "io",
        "handler": "http_tool",
        "inputs": {
          "tool": "date",
          "operation": "now",
          "tz": "UTC"
        },
        "outputs": {
          "result": "cycle.dates.now"
        },
        "timeout_sec": 5
      },
      {
        "name": "get_date_from",
        "type": "io",
        "handler": "http_tool",
        "inputs": {
          "tool": "date",
          "operation": "add",
          "date": "${cycle.dates.now}",
          "days": -3
        },
        "outputs": {
          "result": "cycle.dates.from"
        },
        "timeout_sec": 5
      },
      {
        "name": "fetch_news",
        "type": "io",
        "handler": "http_tool",
        "inputs": {
          "tool": "news_aggregator",
          "operation": "search_news",
          "query": "AI OR LLM OR GPT OR \"large language model\"",
          "providers": ["nyt", "guardian"],
          "from_date": "${cycle.dates.from}",
          "to_date": "${cycle.dates.now}",
          "limit": 5
        },
        "outputs": {
          "articles": "cycle.sources.news"
        },
        "timeout_sec": 20,
        "retry": {
          "max": 2,
          "delay_sec": 5
        }
      },
      {
        "name": "fetch_reddit",
        "type": "io",
        "handler": "http_tool",
        "inputs": {
          "tool": "reddit_intelligence",
          "operation": "multi_search",
          "subreddits": ["MachineLearning", "LocalLLaMA"],
          "query": "AI OR LLM OR GPT",
          "limit_per_sub": 2,
          "time_filter": "week"
        },
        "outputs": {
          "results": "cycle.sources.reddit"
        },
        "timeout_sec": 20,
        "retry": {
          "max": 2,
          "delay_sec": 5
        }
      },
      {
        "name": "fetch_arxiv",
        "type": "io",
        "handler": "http_tool",
        "inputs": {
          "tool": "academic_research_super",
          "operation": "search_papers",
          "query": "LLM OR GPT OR transformer OR \"large language model\"",
          "sources": ["arxiv"],
          "max_results": 5,
          "include_abstracts": false
        },
        "outputs": {
          "results": "cycle.sources.arxiv"
        },
        "timeout_sec": 20,
        "retry": {
          "max": 2,
          "delay_sec": 5
        }
      },
      {
        "name": "fetch_papers_with_code",
        "type": "io",
        "handler": "http_tool",
        "inputs": {
          "tool": "universal_doc_scraper",
          "operation": "extract_page",
          "url": "https://paperswithcode.com/latest"
        },
        "outputs": {
          "content": "cycle.sources.pwc_raw"
        },
        "timeout_sec": 30,
        "retry": {
          "max": 2,
          "delay_sec": 5
        }
      },
      {
        "name": "llm_score_and_rank",
        "type": "io",
        "handler": "http_tool",
        "inputs": {
          "tool": "call_llm",
          "operation": "call",
          "model": "${worker.llm_model}",
          "messages": [
            {
              "role": "system",
              "content": "You are an AI/LLM expert curator. Score items on: 1) Relevance to AI/LLM field (not tangential uses), 2) Novelty/importance, 3) Quality of source. Output ONLY valid JSON array with top 10 items ranked by score (1-10). Format: [{\"source\": \"news|reddit|arxiv|paperswithcode\", \"title\": \"...\", \"url\": \"...\", \"score\": 9.5, \"reason\": \"Brief why this is important\"}]"
            },
            {
              "role": "user",
              "content": "Score and rank these items, return top 10:\n\nNEWS:\n${cycle.sources.news}\n\nREDDIT:\n${cycle.sources.reddit}\n\nARXIV:\n${cycle.sources.arxiv}\n\nPAPERS WITH CODE (extract only paper titles, authors, upvotes and URLs from this text, ignore the rest):\n${cycle.sources.pwc_raw}\n\nReturn ONLY the JSON array of top 10."
            }
          ],
          "temperature": 0.3,
          "max_tokens": 2000
        },
        "outputs": {
          "content": "cycle.analysis.top10_raw"
        },
        "timeout_sec": 60,
        "retry": {
          "max": 2,
          "delay_sec": 10
        }
      },
      {
        "name": "check_top10",
        "type": "decision",
        "decision": {
          "kind": "truthy",
          "input": "${cycle.analysis.top10_raw}"
        }
      },
      {
        "name": "llm_summarize",
        "type": "io",
        "handler": "http_tool",
        "inputs": {
          "tool": "call_llm",
          "operation": "call",
          "model": "${worker.llm_model}",
          "messages": [
            {
              "role": "system",
              "content": "You are a concise technical summarizer. For each item in the JSON array, add a 'summary' field with 2-3 sentences max explaining what it is and why it matters. Keep technical accuracy. Return the same JSON structure with added summaries."
            },
            {
              "role": "user",
              "content": "Add summaries to these top 10 items:\n\n${cycle.analysis.top10_raw}\n\nReturn the complete JSON with summaries added."
            }
          ],
          "temperature": 0.3,
          "max_tokens": 1500
        },
        "outputs": {
          "content": "cycle.analysis.top10_with_summaries"
        },
        "timeout_sec": 60,
        "retry": {
          "max": 2,
          "delay_sec": 10
        }
      },
      {
        "name": "llm_format_report",
        "type": "io",
        "handler": "http_tool",
        "inputs": {
          "tool": "call_llm",
          "operation": "call",
          "model": "${worker.llm_model}",
          "messages": [
            {
              "role": "system",
              "content": "You are a markdown report formatter. Create a beautiful, professional report with: title, date range, introduction paragraph, then numbered list (1-10) with each item formatted as: **#N. [Title](url)** (source) - Score: X/10 - Summary. Add a conclusion paragraph. Use emojis sparingly for readability."
            },
            {
              "role": "user",
              "content": "Format this data into a markdown report:\n\nDate range: ${cycle.dates.from} to ${cycle.dates.now}\n\nTop 10 items:\n${cycle.analysis.top10_with_summaries}\n\nCreate the final markdown report."
            }
          ],
          "temperature": 0.5,
          "max_tokens": 2500
        },
        "outputs": {
          "content": "cycle.result.report"
        },
        "timeout_sec": 60,
        "retry": {
          "max": 2,
          "delay_sec": 10
        }
      },
      {
        "name": "create_table",
        "type": "io",
        "handler": "http_tool",
        "inputs": {
          "tool": "sqlite_db",
          "operation": "execute",
          "db": "worker_ai_curation",
          "query": "CREATE TABLE IF NOT EXISTS curation_reports (id INTEGER PRIMARY KEY AUTOINCREMENT, created_at TEXT NOT NULL, date_from TEXT, date_to TEXT, report_markdown TEXT, top10_json TEXT)"
        },
        "outputs": {
          "success": "cycle.result.table_created"
        },
        "timeout_sec": 5
      },
      {
        "name": "save_report_to_db",
        "type": "io",
        "handler": "http_tool",
        "inputs": {
          "tool": "sqlite_db",
          "operation": "execute",
          "db": "worker_ai_curation",
          "query": "INSERT INTO curation_reports (created_at, date_from, date_to, report_markdown, top10_json) VALUES (datetime('now'), ?, ?, ?, ?)",
          "params": ["${cycle.dates.from}", "${cycle.dates.now}", "${cycle.result.report}", "${cycle.analysis.top10_with_summaries}"]
        },
        "outputs": {
          "success": "cycle.result.db_saved"
        },
        "timeout_sec": 10
      },
      {
        "name": "mark_success",
        "type": "io",
        "handler": "http_tool",
        "inputs": {
          "tool": "date",
          "operation": "now"
        },
        "outputs": {
          "result": "cycle.result.completed_at"
        },
        "timeout_sec": 5
      },
      {
        "name": "mark_failure",
        "type": "io",
        "handler": "http_tool",
        "inputs": {
          "tool": "date",
          "operation": "now"
        },
        "outputs": {
          "result": "cycle.result.failed_at"
        },
        "timeout_sec": 5
      },
      {
        "name": "EXIT",
        "type": "exit"
      }
    ],
    "edges": [
      {"from": "START", "to": "get_date_now"},
      {"from": "get_date_now", "to": "get_date_from"},
      {"from": "get_date_from", "to": "fetch_news"},
      {"from": "fetch_news", "to": "fetch_reddit"},
      {"from": "fetch_reddit", "to": "fetch_arxiv"},
      {"from": "fetch_arxiv", "to": "fetch_papers_with_code"},
      {"from": "fetch_papers_with_code", "to": "llm_score_and_rank"},
      {"from": "llm_score_and_rank", "to": "check_top10"},
      
      {"from": "check_top10", "to": "llm_summarize", "when": "true"},
      {"from": "check_top10", "to": "mark_failure", "when": "false"},
      
      {"from": "llm_summarize", "to": "llm_format_report"},
      {"from": "llm_format_report", "to": "create_table"},
      {"from": "create_table", "to": "save_report_to_db"},
      {"from": "save_report_to_db", "to": "mark_success"},
      
      {"from": "mark_success", "to": "EXIT"},
      {"from": "mark_failure", "to": "EXIT"}
    ]
  },
  "scopes": [
    {
      "name": "dates",
      "reset_on": ["START"],
      "seed": {}
    },
    {
      "name": "sources",
      "reset_on": ["START"],
      "seed": {}
    },
    {
      "name": "analysis",
      "reset_on": ["START"],
      "seed": {}
    },
    {
      "name": "result",
      "reset_on": ["START"],
      "seed": {}
    }
  ],
  "graph_mermaid": "graph TD\n  START-->get_date_now\n  get_date_now-->get_date_from\n  get_date_from-->fetch_news[Fetch News 5 items]\n  fetch_news-->fetch_reddit[Fetch Reddit 2x2 posts]\n  fetch_reddit-->fetch_arxiv[Fetch arXiv 5 papers]\n  fetch_arxiv-->fetch_pwc[Fetch Papers With Code]\n  fetch_pwc-->llm_score[LLM: Score and Rank Top 10]\n  llm_score-->check_top10{Decision: top10 exists?}\n  check_top10-->|true|llm_summarize[LLM: Add Summaries]\n  check_top10-->|false|mark_failure\n  llm_summarize-->llm_format[LLM: Format Markdown Report]\n  llm_format-->create_table[Create DB Table]\n  create_table-->save_db[Save to SQLite]\n  save_db-->mark_success\n  mark_success-->EXIT\n  mark_failure-->EXIT"
}
