# ğŸ¤– AI/LLM Curation Worker v6.3

Architecture hiÃ©rarchique SSOT pour curation automatisÃ©e IA/LLM (â‰¤72h, 4 sources, validation qualitÃ© Sonar, rapports FR).

---

## ğŸ¯ Objectif

Produire quotidiennement un **Top 10 IA/LLM** de haute qualitÃ© :
- **4 sources** : News (NYT/Guardian), Reddit, arXiv, Sonar
- **FraÃ®cheur stricte** : â‰¤ 72 heures
- **Validation qualitÃ©** : score Sonar â‰¥ 7/10 (max 3 tentatives)
- **Rapport FR** : markdown lisible, professionnel, accessible

---

## ğŸ“ Architecture hiÃ©rarchique (SSOT)

### Principe : Single Source of Truth
- **Chaque node dÃ©fini UNE SEULE FOIS** dans son subgraph
- **Pas de duplication** : edges intra-SG dans subgraph, inter-SG dans main
- **Navigation rÃ©cursive** : vue macro â†’ clic boÃ®te â†’ vue dÃ©tail â†’ drill-down infini

```
workers/ai_curation/
â”œâ”€â”€ main.process.json                 (1.8KB)  # Orchestration 5 subgraphs
â”‚
â”œâ”€â”€ config/                           # Configurations
â”‚   â”œâ”€â”€ worker_ctx.json               (248B)   # ModÃ¨les, seuils, DB
â”‚   â””â”€â”€ scopes.json                   (589B)   # Namespaces cycle
â”‚
â”œâ”€â”€ prompts/                          # Data lourdes (LLM prompts)
â”‚   â”œâ”€â”€ gpt_scoring.json              (2.0KB)  # Scoring multi-sources
â”‚   â”œâ”€â”€ sonar_fetch.json              (0.9KB)  # Fetch real-time Sonar
â”‚   â”œâ”€â”€ sonar_validation.json         (1.9KB)  # Validation qualitÃ©
â”‚   â”œâ”€â”€ gpt_format_fr.json            (2.0KB)  # Format rapport FR
â”‚   â””â”€â”€ gpt_merge_report_fr.json      (1.7KB)  # Fusion/dÃ©doublonnage
â”‚
â”œâ”€â”€ subgraphs/                        # Phases autonomes (SSOT)
â”‚   â”œâ”€â”€ 01_init.subgraph.json         (2.1KB)  # Dates + DB setup
â”‚   â”œâ”€â”€ 02_collect.subgraph.json      (4.8KB)  # Fetch 4 sources + filter
â”‚   â”œâ”€â”€ 03_score.subgraph.json        (1.2KB)  # GPT scoring top 10
â”‚   â”œâ”€â”€ 04_validate.subgraph.json     (4.9KB)  # Validation loop Sonar
â”‚   â””â”€â”€ 05_output.subgraph.json       (1.8KB)  # Format FR + save DB
â”‚   â””â”€â”€ 06_enrich.subgraph.json       (5.2KB)  # Enrich primary sources
â”‚
â””â”€â”€ visualization/                    # Mermaid avec emojis
    â”œâ”€â”€ main_global.mmd               (830B)   # Vue macro (5 boÃ®tes)
    â”œâ”€â”€ subgraph_COLLECT.mmd          (1.4KB)  # DÃ©tail COLLECT (4 sources)
    â””â”€â”€ subgraph_VALIDATE.mmd         (1.9KB)  # DÃ©tail VALIDATE
```

**Taille totale** : ~30KB (vs 23KB ancien monolithe)  
**Plus gros fichier** : 4.8KB (02_collect.subgraph.json)

---

## ğŸ¨ Vue globale (5 subgraphs)

```mermaid
graph LR
  START([ğŸš€ START])
  INIT[ğŸ”§ INIT<br>dates + DB setup]
  COLLECT[ğŸ“¦ COLLECT<br>4 sources + filter]
  SCORE[ğŸ¯ SCORE<br>GPT top 10]
  VALIDATE[âœ… VALIDATE<br>Sonar quality check]
  OUTPUT[ğŸ’¾ OUTPUT<br>Format FR + save]
  EXIT([ğŸ EXIT])
  
  START-->INIT
  INIT-->COLLECT
  COLLECT-->SCORE
  SCORE-->VALIDATE
  VALIDATE-->|ğŸ”„ retry|SCORE
  VALIDATE-->|âœ“ success|ENRICH
  VALIDATE-->|ğŸ›‘ retry_exhausted|ENRICH
  ENRICH-->OUTPUT
  OUTPUT-->EXIT
  
  class INIT init
  class COLLECT collect
  class SCORE score
  class VALIDATE validate
  class OUTPUT output
  
  classDef init fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#fff
  classDef collect fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff
  classDef score fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff
  classDef validate fill:#9C27B0,stroke:#7B1FA2,stroke-width:2px,color:#fff
  classDef output fill:#607D8B,stroke:#455A64,stroke-width:2px,color:#fff
```

ğŸ‘† Clic sur une boÃ®te â†’ affiche le dÃ©tail du subgraph

---

## ğŸ” Vue dÃ©tail : COLLECT (exemple)

```mermaid
graph TB
  entry[ğŸ›‚ Entry Point]
  
  fetch_news[ğŸŒ fetch_news<br>NYT + Guardian]
  fetch_reddit[ğŸ’¬ fetch_reddit<br>ML subs]
  fetch_arxiv[ğŸ“„ fetch_arxiv<br>Papers]
  fetch_sonar[ğŸ” fetch_sonar<br>Real-time web]
  
  normalize_sonar[ğŸ”„ normalize_sonar<br>Parse JSON]
  
  filter_news[â±ï¸ filter_news<br>â‰¥ 72h]
  filter_reddit[â±ï¸ filter_reddit<br>â‰¥ 72h]
  filter_arxiv[â±ï¸ filter_arxiv<br>â‰¥ 72h]
  filter_sonar[â±ï¸ filter_sonar<br>â‰¥ 72h]
  
  compute_total[ğŸ“Š compute_total_kept]
  exit[ğŸ›‚ Exit to SCORE]
  
  entry-->fetch_news
  fetch_news-->fetch_reddit
  fetch_reddit-->fetch_arxiv
  fetch_arxiv-->fetch_sonar
  fetch_sonar-->normalize_sonar
  normalize_sonar-->filter_news
  filter_news-->filter_reddit
  filter_reddit-->filter_arxiv
  filter_arxiv-->filter_sonar
  filter_sonar-->compute_total
  compute_total-->exit
  
  class entry entryNode
  class exit exitNode
  class fetch_news,fetch_reddit,fetch_arxiv,fetch_sonar ioNode
  class normalize_sonar,filter_news,filter_reddit,filter_arxiv,filter_sonar,compute_total transformNode
  
  classDef entryNode fill:#90CAF9,stroke:#42A5F5,stroke-width:3px
  classDef exitNode fill:#90CAF9,stroke:#42A5F5,stroke-width:3px
  classDef ioNode fill:#FFEB3B,stroke:#F57F17,stroke-width:2px
  classDef transformNode fill:#81C784,stroke:#388E3C,stroke-width:2px
```

[â—€ Retour vue globale]

---

## ğŸš€ DÃ©marrage rapide

```python
from src.tools.orchestrator import run

# Start worker
run(
    operation="start",
    worker_name="ai_curation",
    worker_file="workers/ai_curation/main.process.json",
    hot_reload=True
)

# Status (avec position actuelle)
status = run(operation="status", worker_name="ai_curation")
print(status)
# â†’ {"status": "running", "current_node": "filter_arxiv", "subgraph": "COLLECT", ...}

# Stop
run(operation="stop", worker_name="ai_curation", stop={"mode": "soft"})
```

---

## ğŸ”„ Workflow dÃ©taillÃ©

### ğŸ”§ 1. INIT (Initialization)
- UTC now â†’ now - 3 jours
- CREATE TABLE IF NOT EXISTS (validation_logs, reports)

### ğŸ“¦ 2. COLLECT (Multi-Source Collection)
- Fetch (4 sources): News, Reddit, arXiv, Sonar
- Normalisation & filtres (â‰¥ ${cycle.dates.from})
- compute_total_kept via tool math

### ğŸ¯ 3. SCORE (GPT Scoring)
- GPT-4o-mini analyse tout â†’ top 10 JSON
- Normalisation â†’ JSON strict
- Stringify top10 pour DB INSERT

### âœ… 4. VALIDATE (Quality Validation Loop)
- Sonar quality â†’ score + feedback
- Log en DB (validation_logs)
- Seuil â‰¥ ${worker.quality_threshold} ?
  - Oui â†’ success
  - Non â†’ increment_retry â†’ retry_count < ${worker.max_retries} ?
    - Oui â†’ exit retry â†’ boucle vers SCORE
    - Non â†’ retry_exhausted â†’ ENRICH

### ğŸ’¾ 5. OUTPUT (Format & Save)
- GPT format FR (markdown) + timestamp
- DB INSERT (reports)

---

## ğŸ—„ï¸ Base de donnÃ©es

SQLite (fichier injectÃ© par runner: ${worker.db_file})

Tables principales:
- validation_logs(id, timestamp, attempt, score, feedback, top10_json)
- reports(id, date_from, date_to, report_markdown, avg_score, retry_count, top10_json, completed_at)

---

## âš™ï¸ Configuration

worker_ctx.json (extrait):
```json
{
  "llm_model": "gpt-4o-mini",
  "sonar_model": "sonar",
  "llm_temperature": 0.3,
  "quality_threshold": 7,
  "max_retries": 3
}
```

---

## ğŸ§­ Visualisation interactive (viewer)

- main_global.mmd â†’ vue macro
- subgraph_COLLECT.mmd â†’ dÃ©tail COLLECT (4 sources)
- subgraph_VALIDATE.mmd â†’ dÃ©tail VALIDATE

CSS dâ€™animation (exemple):
```css
/* Node actuel */
.node.running {
  fill: #FFC107 !important;
  stroke: #FF6F00;
  stroke-width: 3px;
  filter: drop-shadow(0 0 8px #FFC107);
  animation: pulse 1s infinite;
}
```

---

## âœ… Checklist production
- [x] Edges cohÃ©rents (retry, retry_exhausted, success)
- [x] Exits dÃ©clarÃ©s cÃ´tÃ© subgraph VALIDATE
- [x] 4 sources uniquement (docs + prompts + viz)
- [x] JSON stringify avant INSERT DB
- [x] Seuils et retries paramÃ©trÃ©s via worker_ctx

---

## ğŸ—ºï¸ Roadmap

### v6.3 (actuel)
- âœ… Boucle retry robuste + cohÃ©rence 4 sources
- âœ… Prompts harmonisÃ©s
- âœ… Visualisation COLLECT mise Ã  jour

### v7.0 (future)
- [ ] Subgraphs imbriquÃ©s (rÃ©cursion infinie)
- [ ] Conditional subgraphs (switch entre variantes)
- [ ] Parallel subgraphs (exÃ©cution concurrente)

---

**Version**: 6.3.0-ssot  
**DerniÃ¨re mise Ã  jour**: 2025-10-22  
**Auteur**: orchestrator-team
