# ğŸ¤– AI/LLM Curation Worker v6.2

**Architecture hiÃ©rarchique SSOT pour curation automatisÃ©e IA/LLM (â‰¤72h, 5 sources, validation qualitÃ© Sonar, rapports FR).**

---

## ğŸ¯ Objectif

Produire quotidiennement un **Top 10 IA/LLM** de haute qualitÃ© :
- **5 sources** : News (NYT/Guardian), Reddit, arXiv, Papers With Code, Sonar
- **FraÃ®cheur stricte** : â‰¤ 72 heures
- **Validation qualitÃ©** : score Sonar â‰¥ 7/10 (max 3 tentatives)
- **Rapport FR** : markdown lisible, professionnel, accessible

---

## ğŸ“ Architecture hiÃ©rarchique (SSOT)

### Principe : Single Source of Truth
- **Chaque node dÃ©fini UNE SEULE FOIS** dans son subgraph
- **Pas de duplication** : edges intra-SG dans subgraph, inter-SG dans main
- **Navigation rÃ©cursive** : vue macro â†’ clic boÃ®te â†’ vue dÃ©tail â†’ drill-down infini

```
workers/ai_curation/
â”œâ”€â”€ main.process.json                 (1.8KB)  # Orchestration 5 subgraphs
â”‚
â”œâ”€â”€ config/                           # Configurations
â”‚   â”œâ”€â”€ worker_ctx.json               (248B)   # ModÃ¨les, seuils, DB
â”‚   â””â”€â”€ scopes.json                   (589B)   # Namespaces cycle
â”‚
â”œâ”€â”€ prompts/                          # Data lourdes (LLM prompts)
â”‚   â”œâ”€â”€ gpt_scoring.json              (2.1KB)  # Scoring multi-sources
â”‚   â”œâ”€â”€ sonar_fetch.json              (1.3KB)  # Fetch real-time Sonar
â”‚   â”œâ”€â”€ sonar_validation.json         (1.9KB)  # Validation qualitÃ©
â”‚   â”œâ”€â”€ gpt_format_fr.json            (2.0KB)  # Format rapport FR
â”‚   â””â”€â”€ gpt_merge_report_fr.json      (1.7KB)  # Fusion/dÃ©douplonnage
â”‚
â”œâ”€â”€ subgraphs/                        # Phases autonomes (SSOT)
â”‚   â”œâ”€â”€ 01_init.subgraph.json         (2.1KB)  # Dates + DB setup
â”‚   â”œâ”€â”€ 02_collect.subgraph.json      (4.8KB)  # Fetch 5 sources + filter
â”‚   â”œâ”€â”€ 03_score.subgraph.json        (1.2KB)  # GPT scoring top 10
â”‚   â”œâ”€â”€ 04_validate.subgraph.json     (4.4KB)  # Validation loop Sonar
â”‚   â””â”€â”€ 05_output.subgraph.json       (1.8KB)  # Format FR + save DB
â”‚
â”œâ”€â”€ visualization/                    # Mermaid avec emojis
â”‚   â”œâ”€â”€ main_global.mmd               (830B)   # Vue macro (5 boÃ®tes)
â”‚   â”œâ”€â”€ subgraph_COLLECT.mmd          (1.4KB)  # DÃ©tail COLLECT
â”‚   â””â”€â”€ subgraph_VALIDATE.mmd         (1.9KB)  # DÃ©tail VALIDATE
â”‚
â””â”€â”€ README.md                         (ce fichier)
```

**Taille totale** : ~30KB (vs 23KB ancien monolithe)  
**Plus gros fichier** : 4.8KB (02_collect.subgraph.json)

---

## ğŸ¨ Vue globale (5 subgraphs)

```mermaid
graph LR
  START([ğŸš€ START])
  INIT[ğŸ”§ INIT<br>dates + DB setup]
  COLLECT[ğŸ“¦ COLLECT<br>5 sources + filter]
  SCORE[ğŸ¯ SCORE<br>GPT top 10]
  VALIDATE[âœ… VALIDATE<br>Sonar quality check]
  OUTPUT[ğŸ’¾ OUTPUT<br>Format FR + save]
  EXIT([ğŸ EXIT])
  
  START-->INIT
  INIT-->COLLECT
  COLLECT-->SCORE
  SCORE-->VALIDATE
  VALIDATE-->|ğŸ”„ retry|SCORE
  VALIDATE-->|âœ“ success|OUTPUT
  OUTPUT-->EXIT
  
  class INIT init
  class COLLECT collect
  class SCORE score
  class VALIDATE validate
  class OUTPUT output
  
  classDef init fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#fff
  classDef collect fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff
  classDef score fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff
  classDef validate fill:#9C27B0,stroke:#7B1FA2,stroke-width:2px,color:#fff
  classDef output fill:#607D8B,stroke:#455A64,stroke-width:2px,color:#fff
```

ğŸ‘† **Clic sur une boÃ®te** â†’ affiche le dÃ©tail du subgraph

---

## ğŸ” Vue dÃ©tail : COLLECT (exemple)

```mermaid
graph TB
  entry[ğŸšª Entry Point]
  
  fetch_news[ğŸŒ fetch_news<br>NYT + Guardian]
  fetch_reddit[ğŸ’¬ fetch_reddit<br>ML subs]
  fetch_arxiv[ğŸ“„ fetch_arxiv<br>Papers]
  fetch_pwc[ğŸ† fetch_pwc<br>Trending]
  fetch_sonar[ğŸ” fetch_sonar<br>Real-time web]
  
  normalize_sonar[ğŸ”„ normalize_sonar<br>Parse JSON]
  
  filter_news[â±ï¸ filter_news<br>geq 72h]
  filter_reddit[â±ï¸ filter_reddit<br>geq 72h]
  filter_arxiv[â±ï¸ filter_arxiv<br>geq 72h]
  filter_sonar[â±ï¸ filter_sonar<br>geq 72h]
  
  count_pwc[ğŸ“Š count_pwc<br>Pass-through]
  exit[ğŸšª Exit to SCORE]
  
  entry-->fetch_news
  fetch_news-->fetch_reddit
  fetch_reddit-->fetch_arxiv
  fetch_arxiv-->fetch_pwc
  fetch_pwc-->fetch_sonar
  fetch_sonar-->normalize_sonar
  normalize_sonar-->filter_news
  filter_news-->filter_reddit
  filter_reddit-->filter_arxiv
  filter_arxiv-->filter_sonar
  filter_sonar-->count_pwc
  count_pwc-->exit
  
  class entry entryNode
  class exit exitNode
  class fetch_news,fetch_reddit,fetch_arxiv,fetch_pwc,fetch_sonar ioNode
  class normalize_sonar,filter_news,filter_reddit,filter_arxiv,filter_sonar,count_pwc transformNode
  
  classDef entryNode fill:#90CAF9,stroke:#42A5F5,stroke-width:3px
  classDef exitNode fill:#90CAF9,stroke:#42A5F5,stroke-width:3px
  classDef ioNode fill:#FFEB3B,stroke:#F57F17,stroke-width:2px
  classDef transformNode fill:#81C784,stroke:#388E3C,stroke-width:2px
```

[â—€ Retour vue globale]

---

## ğŸš€ DÃ©marrage rapide

```python
from src.tools.orchestrator import run

# Start worker
run(
    operation="start",
    worker_name="ai_curation",
    worker_file="workers/ai_curation/main.process.json",
    hot_reload=True
)

# Status (avec position actuelle)
status = run(operation="status", worker_name="ai_curation")
print(status)
# â†’ {"status": "running", "current_node": "filter_arxiv", "subgraph": "COLLECT", ...}

# Stop
run(operation="stop", worker_name="ai_curation", stop={"mode": "soft"})
```

---

## ğŸ”„ Workflow dÃ©taillÃ©

### ğŸ”§ **1. INIT** (Initialization)
**Nodes** : 4  
**Entry** : `get_date_now`  
**Exit** : `ensure_reports_table`

1. `get_date_now` â†’ UTC ISO now
2. `compute_from_date` â†’ now - 3 jours
3. `ensure_validation_logs_table` â†’ CREATE TABLE IF NOT EXISTS
4. `ensure_reports_table` â†’ CREATE TABLE IF NOT EXISTS

---

### ğŸ“¦ **2. COLLECT** (Multi-Source Collection)
**Nodes** : 11  
**Entry** : `fetch_news`  
**Exit** : `count_pwc`

**Fetch (5 sources)** :
- `fetch_news` â†’ NYT/Guardian (from/to dates)
- `fetch_reddit` â†’ MachineLearning/LocalLLaMA/OpenAI (time_filter=week)
- `fetch_arxiv` â†’ LLM papers (max 30)
- `fetch_pwc` â†’ Trending NLP papers (max 15)
- `fetch_sonar` â†’ Real-time web search (user-only prompt)

**Normalize + Filter (â‰¤72h)** :
- `normalize_sonar` â†’ Parse JSON
- `filter_news/reddit/arxiv/sonar` â†’ Filter by date (â‰¥ ${from})
- `count_pwc` â†’ Pass-through (already trending)

---

### ğŸ¯ **3. SCORE** (GPT Scoring)
**Nodes** : 3  
**Entry** : `llm_gpt_score`  
**Exit** : `json_stringify_top10`

1. `llm_gpt_score` â†’ GPT-4o-mini analyze all sources â†’ top 10
2. `normalize_gpt_score` â†’ Parse JSON response
3. `json_stringify_top10` â†’ Stringify for DB insert (fix v5.5.2)

---

### âœ… **4. VALIDATE** (Quality Validation Loop)
**Nodes** : 10  
**Entry** : `get_validation_timestamp`  
**Exit** : `format_validation_log_message` (success) | `increment_retry` (retry)

**Loop logic** :
```
1. get_validation_timestamp
2. llm_sonar_validate â†’ Sonar quality check
3. normalize_sonar_validation
4. extract_score + extract_feedback
5. insert_validation_log â†’ DB log
6. check_score_threshold â†’ â‰¥ 7 ?
   â†’ TRUE : goto format_validation_log_message (exit success)
   â†’ FALSE : goto increment_retry
7. increment_retry â†’ retry_count++
8. check_retry_limit â†’ < 3 ?
   â†’ TRUE : jump back to SCORE (retry)
   â†’ FALSE : goto format_validation_log_message (accept score)
```

---

### ğŸ’¾ **5. OUTPUT** (Format & Save)
**Nodes** : 3  
**Entry** : `llm_format_fr`  
**Exit** : `save_report`

1. `llm_format_fr` â†’ GPT format rapport FR (markdown)
2. `get_completion_timestamp`
3. `save_report` â†’ DB INSERT (reports table)

---

## ğŸ—„ï¸ Base de donnÃ©es

**DB unique** : `ai_curation_reports.db` (dÃ©fini dans worker_ctx.json)

### Table: validation_logs
```sql
CREATE TABLE validation_logs (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  timestamp TEXT NOT NULL,
  attempt INTEGER,
  score REAL,
  feedback TEXT,
  top10_json TEXT
);
```

### Table: reports
```sql
CREATE TABLE reports (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  date_from TEXT,
  date_to TEXT,
  report_markdown TEXT,
  avg_score REAL,
  retry_count INTEGER,
  top10_json TEXT,
  completed_at TEXT
);
```

---

## ğŸ¯ Configuration

### worker_ctx.json
```json
{
  "llm_model": "gpt-4o-mini",
  "sonar_model": "sonar",
  "llm_temperature": 0.3,
  "quality_threshold": 7,
  "max_retries": 3,
  "db_name": "ai_curation_reports"
}
```

### Modifier seuils
- **quality_threshold** : score minimum (dÃ©faut: 7)
- **max_retries** : tentatives max scoring (dÃ©faut: 3)
- **llm_model** : modÃ¨le GPT (gpt-4o-mini, gpt-4, etc.)

---

## ğŸ¨ Visualisation interactive (viewer)

### Principe : Navigation hiÃ©rarchique

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Vue MACRO (main.process.json)      â”‚
â”‚                                     â”‚
â”‚  ğŸš€ â†’ ğŸ”§ â†’ ğŸ“¦ â†’ ğŸ¯ â†’ âœ… â†’ ğŸ’¾ â†’ ğŸ â”‚
â”‚             â†‘ (vous Ãªtes ici)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        ğŸ‘† CLIC sur ğŸ“¦ COLLECT
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Vue DÃ‰TAIL (02_collect.subgraph)   â”‚
â”‚                                     â”‚
â”‚  ğŸŒ â†’ ğŸ’¬ â†’ ğŸ“„ â†’ ğŸ† â†’ ğŸ”           â”‚
â”‚                       â†“             â”‚
â”‚         â±ï¸ â†’ â±ï¸ â†’ â±ï¸ â†’ â±ï¸ â†’ ğŸ“Š     â”‚
â”‚                  â†‘ (node actuel)    â”‚
â”‚                                     â”‚
â”‚  [â—€ Retour vue globale]            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### API pour viewer

```python
# 1. Charger le process complet
process = load_process_with_imports("workers/ai_curation/main.process.json")

# 2. Status temps rÃ©el
status = run(operation="status", worker_name="ai_curation")
# â†’ {"current_node": "filter_arxiv", "cycle_id": "cycle_001", ...}

# 3. Identifier le subgraph du node actuel
current_sg = find_subgraph_for_node(process, status["current_node"])
# â†’ "COLLECT"

# 4. Charger le dÃ©tail du subgraph
sg_detail = load_subgraph(process, "COLLECT")
# â†’ {nodes: [...], edges: [...], interface: {...}}

# 5. Highlight dans SVG
highlight_node_in_svg("main_global.svg", "COLLECT", status="running")
highlight_node_in_svg("subgraph_COLLECT.svg", "filter_arxiv", status="running")
```

### Animation trail (CSS dynamique)

```css
/* Node actuel */
.node.running {
  fill: #FFC107 !important;
  stroke: #FF6F00;
  stroke-width: 3px;
  filter: drop-shadow(0 0 8px #FFC107);
  animation: pulse 1s infinite;
}

/* Nodes traversÃ©s */
.node.visited {
  opacity: 0.7;
  fill: #4CAF50;
}

/* Edge active */
.edge.active {
  stroke: #FFC107;
  stroke-width: 4px;
  animation: dash 1s linear infinite;
}

@keyframes pulse {
  0%, 100% { transform: scale(1); }
  50% { transform: scale(1.1); }
}

@keyframes dash {
  to { stroke-dashoffset: -20; }
}
```

---

## ğŸ“Š ObservabilitÃ©

### Logs orchestrateur
```bash
tail -f logs/worker_ai_curation.log
```

### Query validation logs
```sql
SELECT timestamp, attempt, score, substr(feedback,1,100)
FROM validation_logs
ORDER BY id DESC
LIMIT 10;
```

### Query reports
```sql
SELECT id, date_from, date_to, avg_score, retry_count, completed_at
FROM reports
ORDER BY id DESC
LIMIT 5;
```

### MÃ©triques temps rÃ©el (via status)
```python
status = run(operation="status", worker_name="ai_curation")
print(status)
# â†’ {
#   "status": "running",
#   "current_node": "filter_arxiv",
#   "subgraph": "COLLECT",
#   "cycle_id": "cycle_001",
#   "heartbeat": "2025-01-19 23:15:00.123456",
#   "pid": 12345
# }
```

---

## ğŸ”§ DÃ©veloppement

### Modifier prompts
Ã‰diter directement `prompts/*.json`, hot-reload applique les changements au prochain cycle.

### Ajouter une source
1. Ã‰diter `subgraphs/02_collect.subgraph.json` (ajouter node fetch + filter)
2. Mettre Ã  jour prompt `prompts/gpt_scoring.json` (mentionner la nouvelle source)
3. Tester : `run(operation="start", worker_name="test_collect", ...)`

### Debug hiÃ©rarchique
```python
# Enable debug mode
run(operation="debug", worker_name="ai_curation", debug={
    "action": "enable",
    "breakpoints": [{"node": "llm_sonar_validate"}]
})

# Step-by-step (vue globale ou dÃ©tail selon node)
run(operation="debug", worker_name="ai_curation", debug={"action": "step"})
```

---

## âœ… Checklist production

### Architecture
- [x] Tous fichiers < 7KB (max: 4.8KB)
- [x] SSOT strict (pas de duplication nodes/edges)
- [x] Subgraphs autonomes avec interface entry/exit
- [x] Navigation hiÃ©rarchique (vue macro â†’ drill-down dÃ©tail)

### Fonctionnel
- [x] Transforms avec HandlerError
- [x] Prompts Sonar user-only
- [x] JSON stringify avant INSERT DB (fix v5.5.2)
- [x] Seuil qualitÃ© â‰¥ 7/10
- [x] Retry loop max 3Ã—
- [x] FraÃ®cheur stricte â‰¤72h (API + moteur)
- [x] 5 sources collectÃ©es
- [x] Rapport FR format strict

### Visualisation
- [x] Mermaid avec emojis bien choisis
- [x] LÃ©gende couleurs par phase
- [x] SVG gÃ©nÃ©rÃ©s (main_global + dÃ©tails subgraphs)
- [x] Trail animation CSS (running/visited/active)

---

## ğŸ¯ Roadmap

### v6.2 (actuel) âœ…
- [x] Architecture hiÃ©rarchique SSOT
- [x] 5 subgraphs autonomes
- [x] Visualisation Mermaid avec emojis
- [x] Navigation drill-down rÃ©cursive

### v6.3 (Ã  venir)
- [ ] Viewer web interactif (SVG cliquable + trail temps rÃ©el)
- [ ] SSE pour animation live (nodes s'allument/Ã©teignent)
- [ ] Breadcrumb navigation (vue globale â†” dÃ©tail)
- [ ] Export SVG animÃ© (GIF/video du trail complet)

### v7.0 (future)
- [ ] Subgraphs imbriquÃ©s (rÃ©cursion infinie)
- [ ] Conditional subgraphs (switch entre variantes)
- [ ] Parallel subgraphs (exÃ©cution concurrente)

---

**Version**: 6.2.0-hierarchical-ssot  
**DerniÃ¨re mise Ã  jour**: 2025-01-19  
**Auteur**: orchestrator-team
