# ðŸ¤– AI/LLM Curation Worker

**Worker d'orchestration pour la curation automatisÃ©e des actualitÃ©s IA/LLM**

---

## ðŸ“‹ Description

Worker orchestrÃ© qui collecte, score et valide automatiquement les actualitÃ©s IA/LLM des 3 derniers jours depuis 5 sources diffÃ©rentes, avec validation qualitÃ© par Perplexity Sonar et gÃ©nÃ©ration d'un rapport en franÃ§ais.

---

## ðŸŽ¯ Architecture

### **Worker**
- **Nom** : `ai_curation`
- **Type** : One-shot (EXIT aprÃ¨s exÃ©cution)
- **Base de donnÃ©es** : `worker_ai_curation.db`

### **Process**
- **Fichier** : `main.process.json`
- **Version** : 6.0.1-single-db
- **Architecture** : Modulaire avec $import

---

## ðŸ“Š Sources de donnÃ©es (5)

1. **ðŸ“° News** (NYT + Guardian) â€” 8 articles
2. **ðŸ’¬ Reddit** (MachineLearning, LocalLLaMA, OpenAI) â€” 3 posts/sub
3. **ðŸ“„ arXiv** (papers acadÃ©miques) â€” 8 papers
4. **ðŸ’» Papers With Code** (trending papers)
5. **ðŸŒ Sonar** (Perplexity real-time web search) â€” 8-10 items

---

## ðŸ”„ Workflow

### **Phase 1 : Collecte** (30-60s)
- Fetch 5 sources en parallÃ¨le
- Parse et normalisation

### **Phase 2 : Scoring Loop** (avec retry)
```
SCORING_LOOP
  â†“
  GPT-4o-mini scoring (Top 10)
  â†“
  Sonar validation (score 1-10)
  â†“
  Score >= 7 ? â†’ [OUI] Format rapport FR â†’ EXIT
               â†’ [NON] Retry < 3 ? â†’ [OUI] BACK TO LOOP
                                   â†’ [NON] Format rapport â†’ EXIT
```

**CritÃ¨res de scoring** (GPT-4o-mini) :
- **Pertinence** (40%) : IA/LLM core (pas applications tangentielles)
- **NouveautÃ©** (30%) : Breaking news > recherche rÃ©cente
- **Source Quality** (20%) : arXiv > GitHub > News > Reddit
- **DiversitÃ©** (10%) : Mix de sources

**Validation Sonar** :
- Score 1-10 avec feedback dÃ©taillÃ©
- Seuil : **>= 7/10**
- Max retries : **3**

### **Phase 3 : Rapport** (30-60s)
- GÃ©nÃ©ration rapport markdown en franÃ§ais (GPT-4o-mini)
- Format strict : Titre + Note + RÃ©sumÃ© + URL Ã— 10 items
- Sauvegarde DB + completion

---

## ðŸ“ Structure du rÃ©pertoire

```
workers/ai_curation/
â”œâ”€â”€ main.process.json          # Process principal (avec $import)
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ worker_ctx.json         # Configuration worker
â”‚   â””â”€â”€ scopes.json             # Scopes lifecycle
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ sonar_fetch.json        # Prompt Sonar search
â”‚   â”œâ”€â”€ gpt_scoring.json        # Prompt GPT scoring
â”‚   â”œâ”€â”€ sonar_validation.json   # Prompt Sonar validation
â”‚   â””â”€â”€ gpt_format_fr.json      # Prompt format rapport FR
â””â”€â”€ README.md                   # Ce fichier
```

---

## ðŸ—„ï¸ Base de donnÃ©es

### **worker_ai_curation.db**

#### Table `validation_logs`
Logs des tentatives de validation Sonar (retry loop).

```sql
CREATE TABLE validation_logs (
  id INTEGER PRIMARY KEY,
  timestamp TEXT NOT NULL,
  attempt INTEGER,
  score REAL,
  feedback TEXT,      -- Feedback Sonar complet
  top10_json TEXT     -- Top 10 Ã  cette tentative
);
```

#### Table `reports`
Rapports finaux gÃ©nÃ©rÃ©s.

```sql
CREATE TABLE reports (
  id INTEGER PRIMARY KEY,
  created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,
  date_from TEXT,
  date_to TEXT,
  report_markdown TEXT,  -- Rapport complet en franÃ§ais
  avg_score REAL,
  retry_count INTEGER,
  top10_json TEXT,
  completed_at TEXT
);
```

---

## ðŸš€ Lancement

### **Start**
```python
from src.tools.orchestrator import run

result = run(
    operation="start",
    worker_name="ai_curation",
    worker_file="workers/ai_curation/main.process.json",
    hot_reload=True
)
```

### **Status**
```python
status = run(
    operation="status",
    worker_name="ai_curation"
)
```

### **Stop**
```python
stop = run(
    operation="stop",
    worker_name="ai_curation",
    stop={"mode": "soft"}
)
```

---

## ðŸ“Š Exemple de rapport

```markdown
# ðŸ¤– Top 10 IA/LLM â€” 2025-10-15 au 2025-10-18

**Score de qualitÃ©:** 7.6/10 | **Tentatives:** 0 | **Date:** 2025-10-18

---

## ðŸ“Œ Top 10 SÃ©lection (5 sources: News, Reddit, arXiv, Papers With Code, Sonar)

**1. Design Agentique de Machines Compositives** â€” Note: 9.0/10  
*Cette recherche propose une nouvelle perspective sur la crÃ©ation de machines par les LLM, reprÃ©sentant une avancÃ©e fondamentale dans les capacitÃ©s de l'IA.*  
ðŸ”— Source: [arxiv.org](http://arxiv.org/abs/2510.14980v1)

**2. L'Attention est Tout Ce Dont Vous Avez Besoin pour le Cache KV dans les LLM en Diffusion** â€” Note: 8.5/10  
*Cet article prÃ©sente des amÃ©liorations dans la gestion du cache KV pour les LLM, augmentant ainsi l'efficacitÃ© des modÃ¨les de diffusion.*  
ðŸ”— Source: [arxiv.org](http://arxiv.org/abs/2510.14973v1)

[...8 autres items]

---

## âœ… Ã‰valuation QualitÃ©

**Score final:** 7.6/10  
**Nombre de tentatives:** 0  
**ValidÃ© le:** 2025-10-18T21:22:10

---

## ðŸ” Tendances clÃ©s

*Les thÃ¨mes principaux incluent des avancÃ©es dans la conception agentique des LLM, l'amÃ©lioration de l'efficacitÃ© des modÃ¨les via des techniques de cache optimisÃ©es...*
```

---

## âš™ï¸ Configuration

### **worker_ctx.json**
```json
{
  "timezone": "UTC",
  "llm_model": "gpt-4o-mini",
  "sonar_model": "sonar",
  "llm_temperature": 0.3,
  "quality_threshold": 7,
  "max_retries": 3,
  "db_name": "worker_ai_curation"
}
```

### **Scopes**
- `dates` : Date de collecte (from/now)
- `sources` : DonnÃ©es sources brutes
- `scoring` : RÃ©sultats scoring GPT
- `validation` : RÃ©sultats validation Sonar
- `result` : Rapport final
- `meta` : MÃ©tadonnÃ©es (retry_count, timestamps)

---

## ðŸ“ˆ MÃ©triques

### **Temps d'exÃ©cution typique**
- **Total** : 70-120 secondes
  - Collecte : 30-60s
  - Scoring loop : 20-40s (1-3 tentatives)
  - Format rapport : 15-30s

### **CoÃ»ts LLM**
- **GPT-4o-mini** : ~2-3 appels (scoring + format)
- **Sonar** : ~1-3 appels (fetch + validation retry)

---

## ðŸ”§ DÃ©pannage

### **Retry loop infini**
Si le worker boucle > 3 fois :
- VÃ©rifier les logs `validation_logs`
- Sonar retourne probablement du texte au lieu de JSON
- Solution : amÃ©liorer le prompt `prompts/sonar_validation.json`

### **Score toujours < 7**
- Sources trop faibles (vÃ©rifier diversitÃ©)
- CritÃ¨res trop stricts (ajuster seuil Ã  6.5)

### **Parse failed sur top10**
- GPT-4o-mini a retournÃ© du texte au lieu de JSON
- VÃ©rifier `prompts/gpt_scoring.json` (instruction "ONLY JSON")

---

## ðŸ“ Changelog

### v6.0.1 (2025-10-18)
- âœ… Base unique `worker_ai_curation.db`
- âœ… Architecture modulaire avec $import
- âœ… Retry loop avec validation Sonar
- âœ… Rapport franÃ§ais formatÃ©
- âœ… 5 sources (ajout Sonar)

---

## ðŸ“š Voir aussi

- [orchestrator_tool_design.md](../../membank/orchestrator_tool_design.md) â€” Specs orchestrator
- [orchestrator_process_schema.md](../../membank/orchestrator_process_schema.md) â€” Format JSON process
- [orchestrator_mcp_error_handling.md](../../membank/orchestrator_mcp_error_handling.md) â€” Gestion erreurs

---

**Status : âœ… Production-ready**
