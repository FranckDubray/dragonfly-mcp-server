{
  "version": "1.0",
  "process_version": "4.0.0-sonar-validation",
  "metadata": {
    "description": "AI/LLM Curation avec Perplexity Sonar (top 10 + validation qualit√©)",
    "author": "orchestrator-production",
    "features": [
      "Multi-source aggregation (News, Reddit, arXiv)",
      "GPT-4o-mini scoring + Perplexity Sonar top 10",
      "Merge & deduplication",
      "Validation qualit√© par Sonar (score >= 7/10)",
      "Retry loop si qualit√© insuffisante",
      "DB d√©di√©e avec metadata"
    ]
  },
  "worker_ctx": {
    "timezone": "UTC",
    "llm_model": "gpt-4o-mini",
    "sonar_model": "sonar",
    "llm_temperature": 0.3,
    "quality_threshold": 7,
    "max_retries": 3
  },
  "graph": {
    "nodes": [
      {"name": "START", "type": "start"},
      {
        "name": "get_date_now",
        "type": "io",
        "handler": "http_tool",
        "inputs": {"tool": "date", "operation": "now", "tz": "UTC"},
        "outputs": {"result": "cycle.dates.now"},
        "timeout_sec": 10
      },
      {
        "name": "get_date_from",
        "type": "io",
        "handler": "http_tool",
        "inputs": {"tool": "date", "operation": "add", "date": "${cycle.dates.now}", "days": -3},
        "outputs": {"result": "cycle.dates.from"},
        "timeout_sec": 10
      },
      {
        "name": "fetch_news",
        "type": "io",
        "handler": "http_tool",
        "inputs": {
          "tool": "news_aggregator",
          "operation": "search_news",
          "query": "AI OR LLM OR GPT OR \"large language model\"",
          "providers": ["nyt", "guardian"],
          "from_date": "${cycle.dates.from}",
          "to_date": "${cycle.dates.now}",
          "limit": 5
        },
        "outputs": {"articles": "cycle.sources.news"},
        "timeout_sec": 30,
        "retry": {"max": 2, "delay_sec": 5}
      },
      {
        "name": "fetch_reddit",
        "type": "io",
        "handler": "http_tool",
        "inputs": {
          "tool": "reddit_intelligence",
          "operation": "multi_search",
          "subreddits": ["MachineLearning", "LocalLLaMA"],
          "query": "AI OR LLM OR GPT",
          "limit_per_sub": 2,
          "time_filter": "week"
        },
        "outputs": {"results": "cycle.sources.reddit"},
        "timeout_sec": 30,
        "retry": {"max": 2, "delay_sec": 5}
      },
      {
        "name": "fetch_arxiv",
        "type": "io",
        "handler": "http_tool",
        "inputs": {
          "tool": "academic_research_super",
          "operation": "search_papers",
          "query": "LLM OR GPT OR transformer OR \"large language model\"",
          "sources": ["arxiv"],
          "max_results": 5,
          "include_abstracts": false
        },
        "outputs": {"results": "cycle.sources.arxiv"},
        "timeout_sec": 30,
        "retry": {"max": 2, "delay_sec": 5}
      },
      {
        "name": "SCORING_LOOP",
        "type": "transform",
        "handler": "set_value",
        "inputs": {"value": "scoring"},
        "outputs": {"result": "cycle.meta.phase"}
      },
      {
        "name": "llm_gpt_score",
        "type": "io",
        "handler": "http_tool",
        "inputs": {
          "tool": "call_llm",
          "operation": "call",
          "model": "${worker.llm_model}",
          "messages": [
            {
              "role": "system",
              "content": "You are an AI/LLM expert curator. Score items on: 1) Relevance to AI/LLM field (not tangential uses), 2) Novelty/importance, 3) Quality of source. Output ONLY valid JSON array with top 10 items ranked by score (1-10). Format: [{\"source\": \"news|reddit|arxiv\", \"title\": \"...\", \"url\": \"...\", \"score\": 9.5, \"reason\": \"Brief why important\"}]. Be selective and critical."
            },
            {
              "role": "user",
              "content": "Score and rank these items, return EXACTLY top 10 as JSON array:\n\nNEWS:\n${cycle.sources.news}\n\nREDDIT:\n${cycle.sources.reddit}\n\nARXIV:\n${cycle.sources.arxiv}\n\nReturn ONLY the JSON array of top 10."
            }
          ],
          "temperature": 0.3,
          "max_tokens": 2000
        },
        "outputs": {"content": "cycle.scoring.gpt_raw"},
        "timeout_sec": 90,
        "retry": {"max": 2, "delay_sec": 10}
      },
      {
        "name": "normalize_gpt",
        "type": "transform",
        "handler": "normalize_llm_output",
        "inputs": {"content": "${cycle.scoring.gpt_raw}", "expected_format": "json", "fallback_value": []},
        "outputs": {"parsed": "cycle.scoring.gpt_top10", "success": "cycle.scoring.gpt_ok"}
      },
      {
        "name": "llm_sonar_top10",
        "type": "io",
        "handler": "http_tool",
        "inputs": {
          "tool": "call_llm",
          "operation": "call",
          "model": "${worker.sonar_model}",
          "messages": [
            {
              "role": "system",
              "content": "You are Perplexity Sonar with real-time web access. Find and curate the top 10 most important AI/LLM developments from the last 3 days. Focus on: new research papers, major announcements, significant discussions, technical breakthroughs. Output ONLY valid JSON array: [{\"source\": \"web|twitter|github|arxiv\", \"title\": \"...\", \"url\": \"...\", \"score\": 9.5, \"reason\": \"Why important\"}]"
            },
            {
              "role": "user",
              "content": "Search the web for top 10 AI/LLM developments from the last 3 days (since ${cycle.dates.from}). Return ONLY JSON array with your top 10 picks."
            }
          ],
          "temperature": 0.3,
          "max_tokens": 2000
        },
        "outputs": {"content": "cycle.scoring.sonar_raw"},
        "timeout_sec": 90,
        "retry": {"max": 2, "delay_sec": 10}
      },
      {
        "name": "normalize_sonar",
        "type": "transform",
        "handler": "normalize_llm_output",
        "inputs": {"content": "${cycle.scoring.sonar_raw}", "expected_format": "json", "fallback_value": []},
        "outputs": {"parsed": "cycle.scoring.sonar_top10", "success": "cycle.scoring.sonar_ok"}
      },
      {
        "name": "merge_results",
        "type": "transform",
        "handler": "set_value",
        "inputs": {"value": "${cycle.scoring.gpt_top10}"},
        "outputs": {"result": "cycle.analysis.merged_top10"}
      },
      {
        "name": "check_parse_success",
        "type": "decision",
        "decision": {
          "kind": "truthy",
          "input": "${cycle.scoring.gpt_ok}"
        }
      },
      {
        "name": "llm_sonar_validate",
        "type": "io",
        "handler": "http_tool",
        "inputs": {
          "tool": "call_llm",
          "operation": "call",
          "model": "${worker.sonar_model}",
          "messages": [
            {
              "role": "system",
              "content": "You are a quality validator for AI/LLM curation. Analyze this top 10 list and rate its overall quality on a scale of 1-10 based on: relevance to AI/LLM field, novelty, source quality, diversity of topics. Be critical. Return ONLY a JSON object: {\"score\": 8.5, \"feedback\": \"Brief assessment\"}"
            },
            {
              "role": "user",
              "content": "Validate this AI/LLM top 10 curation:\n\nGPT-4o-mini picks:\n${cycle.scoring.gpt_top10}\n\nSonar picks:\n${cycle.scoring.sonar_top10}\n\nRate the overall quality (1-10). Return ONLY JSON: {\"score\": X, \"feedback\": \"...\"}."
            }
          ],
          "temperature": 0.2,
          "max_tokens": 500
        },
        "outputs": {"content": "cycle.validation.sonar_raw"},
        "timeout_sec": 60,
        "retry": {"max": 2, "delay_sec": 10}
      },
      {
        "name": "normalize_validation",
        "type": "transform",
        "handler": "normalize_llm_output",
        "inputs": {"content": "${cycle.validation.sonar_raw}", "expected_format": "json", "fallback_value": {"score": 0}},
        "outputs": {"parsed": "cycle.validation.sonar_result"}
      },
      {
        "name": "extract_score",
        "type": "transform",
        "handler": "extract_field",
        "inputs": {"data": "${cycle.validation.sonar_result}", "path": "score", "default": 0},
        "outputs": {"value": "cycle.validation.sonar_score"}
      },
      {
        "name": "check_quality",
        "type": "decision",
        "decision": {
          "kind": "compare",
          "input": "${cycle.validation.sonar_score}",
          "operator": ">=",
          "value": 7
        }
      },
      {
        "name": "check_retry",
        "type": "decision",
        "decision": {
          "kind": "compare",
          "input": "${cycle.meta.retry_count}",
          "operator": "<",
          "value": 3
        }
      },
      {
        "name": "increment",
        "type": "transform",
        "handler": "increment",
        "inputs": {"value": "${cycle.meta.retry_count}"},
        "outputs": {"result": "cycle.meta.retry_count"}
      },
      {
        "name": "llm_format",
        "type": "io",
        "handler": "http_tool",
        "inputs": {
          "tool": "call_llm",
          "operation": "call",
          "model": "${worker.llm_model}",
          "messages": [
            {
              "role": "system",
              "content": "Create a professional markdown report with: # Title, date range, intro paragraph, two sections (## GPT-4o-mini Top 10, ## Perplexity Sonar Top 10), each with numbered list **#N. [Title](url)** (source) - Score: X/10 - Brief summary. Add conclusion with quality assessment."
            },
            {
              "role": "user",
              "content": "Format markdown report:\n\nDate: ${cycle.dates.from} to ${cycle.dates.now}\n\nGPT-4o-mini picks:\n${cycle.scoring.gpt_top10}\n\nSonar picks:\n${cycle.scoring.sonar_top10}\n\nValidation by Sonar: ${cycle.validation.sonar_result}\n\nCreate the final report."
            }
          ],
          "temperature": 0.5,
          "max_tokens": 3000
        },
        "outputs": {"content": "cycle.result.report"},
        "timeout_sec": 90,
        "retry": {"max": 2, "delay_sec": 10}
      },
      {
        "name": "save_report",
        "type": "io",
        "handler": "http_tool",
        "inputs": {
          "tool": "sqlite_db",
          "operation": "execute",
          "db": "ai_curation_reports.db",
          "query": "INSERT INTO reports (date_from, date_to, report_markdown, avg_score, retry_count) VALUES (?, ?, ?, ?, ?)",
          "params": [
            "${cycle.dates.from}",
            "${cycle.dates.now}",
            "${cycle.result.report}",
            "${cycle.validation.sonar_score}",
            "${cycle.meta.retry_count}"
          ]
        },
        "outputs": {"success": "cycle.result.saved"},
        "timeout_sec": 15
      },
      {
        "name": "mark_success",
        "type": "transform",
        "handler": "set_value",
        "inputs": {"value": "Success"},
        "outputs": {"result": "cycle.result.status"}
      },
      {
        "name": "mark_fail",
        "type": "transform",
        "handler": "set_value",
        "inputs": {"value": "Parse failed"},
        "outputs": {"result": "cycle.result.status"}
      },
      {"name": "EXIT", "type": "exit"}
    ],
    "edges": [
      {"from": "START", "to": "get_date_now"},
      {"from": "get_date_now", "to": "get_date_from"},
      {"from": "get_date_from", "to": "fetch_news"},
      {"from": "fetch_news", "to": "fetch_reddit"},
      {"from": "fetch_reddit", "to": "fetch_arxiv"},
      {"from": "fetch_arxiv", "to": "SCORING_LOOP"},
      
      {"from": "SCORING_LOOP", "to": "llm_gpt_score"},
      {"from": "llm_gpt_score", "to": "normalize_gpt"},
      {"from": "normalize_gpt", "to": "llm_sonar_top10"},
      {"from": "llm_sonar_top10", "to": "normalize_sonar"},
      {"from": "normalize_sonar", "to": "merge_results"},
      {"from": "merge_results", "to": "check_parse_success"},
      
      {"from": "check_parse_success", "to": "llm_sonar_validate", "when": "true"},
      {"from": "check_parse_success", "to": "mark_fail", "when": "false"},
      
      {"from": "llm_sonar_validate", "to": "normalize_validation"},
      {"from": "normalize_validation", "to": "extract_score"},
      {"from": "extract_score", "to": "check_quality"},
      
      {"from": "check_quality", "to": "llm_format", "when": "true"},
      {"from": "check_quality", "to": "check_retry", "when": "false"},
      
      {"from": "check_retry", "to": "increment", "when": "true"},
      {"from": "check_retry", "to": "llm_format", "when": "false"},
      
      {"from": "increment", "to": "SCORING_LOOP"},
      
      {"from": "llm_format", "to": "save_report"},
      {"from": "save_report", "to": "mark_success"},
      {"from": "mark_success", "to": "EXIT"},
      {"from": "mark_fail", "to": "EXIT"}
    ],
    "scopes": [
      {"name": "dates", "reset_on": [], "seed": {}},
      {"name": "sources", "reset_on": [], "seed": {}},
      {"name": "scoring", "reset_on": [], "seed": {}},
      {"name": "analysis", "reset_on": [], "seed": {}},
      {"name": "validation", "reset_on": [], "seed": {}},
      {"name": "result", "reset_on": [], "seed": {}},
      {"name": "meta", "reset_on": [], "seed": {"retry_count": 0}}
    ]
  },
  "graph_mermaid": "graph TD\n  START --> dates[Get Dates]\n  dates --> news[Fetch News]\n  news --> reddit[Fetch Reddit]\n  reddit --> arxiv[Fetch arXiv]\n  arxiv --> scoring_loop[üîÑ SCORING LOOP]\n  scoring_loop --> gpt[ü§ñ GPT-4o-mini: Score]\n  gpt --> norm_gpt[Parse GPT]\n  norm_gpt --> sonar_top[üîÆ Sonar: Top 10]\n  sonar_top --> norm_sonar[Parse Sonar]\n  norm_sonar --> merge[Merge Results]\n  merge --> parse_ok{Parse OK?}\n  parse_ok -->|false| fail[‚ùå Fail]\n  parse_ok -->|true| validate[üîÆ Sonar: Validate]\n  validate --> extract[Extract Score]\n  extract --> quality{Score >= 7?}\n  quality -->|true ‚úÖ| format[ü§ñ Format Report]\n  quality -->|false ‚ùå| retry{retry < 3?}\n  retry -->|true üîÅ| incr[retry++]\n  incr --> scoring_loop\n  retry -->|false üõë| format\n  format --> save[üíæ Save DB]\n  save --> success[‚úÖ Success]\n  success --> EXIT\n  fail --> EXIT\n  style START fill:#90EE90\n  style EXIT fill:#90EE90\n  style scoring_loop fill:#87CEEB\n  style incr fill:#FFD700\n  style quality fill:#FFA500\n  style retry fill:#FFA500"
}
